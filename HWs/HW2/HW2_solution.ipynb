{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each task is worth 5 points, 20 points in total. Additionally, some tasks allow you to get a bonus point, that **can not** increase your total score for the homework beyond the maximum, but can compensate for some occasionally lost points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: multiple comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A randomized, double-blind experiment was conducted to assess the\n",
    "effectiveness of several drugs for reducing postoperative nausea. The\n",
    "data are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Number of Patients</th>\n",
       "      <th>Incidence of Nausea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Placebo</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chlorpromazine</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dimenhydrinate</td>\n",
       "      <td>85</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pentobarbital (100 mg)</td>\n",
       "      <td>67</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pentobarbital (150 mg)</td>\n",
       "      <td>85</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Drug  Number of Patients  Incidence of Nausea\n",
       "0                 Placebo                  80                   45\n",
       "1          Chlorpromazine                  75                   26\n",
       "2          Dimenhydrinate                  85                   52\n",
       "3  Pentobarbital (100 mg)                  67                   35\n",
       "4  Pentobarbital (150 mg)                  85                   37"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'Drug': ['Placebo', 'Chlorpromazine', 'Dimenhydrinate', 'Pentobarbital (100 mg)', 'Pentobarbital (150 mg)'],\n",
    "                    'Number of Patients': [80, 75, 85, 67, 85],\n",
    "                    'Incidence of Nausea': [45, 26, 52, 35, 37]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test each drug versus the placebo at the 5% level. Also, report\n",
    "the estimated odds–ratios. Summarize your findings. (2 points)\n",
    "2. Use the Bonferroni and the FDR method to adjust for multiple\n",
    "testing. (Beecher (1959)) (3 points)\n",
    "3. Reproduce plot similar to Figure 10.6 from the book, displaying observed $p$-values and different thresholds used (1 bonus point)\n",
    "\n",
    "*Hint*. Use simple $H_0$: \"$p_{drug} = p_{placebo}$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Mendel's peas case. Hence, Pearson's Chi-squared test used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value is 0.011279921768145679\n",
      "reject the null hypothesis at the 5% level\n",
      "odds-ratio is 2.423076923076923\n"
     ]
    }
   ],
   "source": [
    "# Chlorpromazine:\n",
    "from scipy.stats import chi2_contingency \n",
    "   \n",
    "data = [[45, 26], [35, 49]] \n",
    "stat, p, dof, expected = chi2_contingency(data) \n",
    "  \n",
    "alpha = 0.05\n",
    "print(\"p value is \" + str(p)) \n",
    "if p <= alpha: \n",
    "    print('reject the null hypothesis at the 5% level') \n",
    "else: \n",
    "    print('fail to reject the null hypothesis under the 5% level')\n",
    "\n",
    "odds_ratio = (45/35)/(26/49)\n",
    "print ('odds-ratio is', odds_ratio)\n",
    "\n",
    "p1 = str(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value is 0.6281776400799568\n",
      "fail to reject the null hypothesis under the 5% level\n",
      "odds-ratio is 0.815934065934066\n"
     ]
    }
   ],
   "source": [
    "# Dimenhydrinate:\n",
    "from scipy.stats import chi2_contingency \n",
    "   \n",
    "data = [[45, 52], [35, 33]] \n",
    "stat, p, dof, expected = chi2_contingency(data) \n",
    "  \n",
    "alpha = 0.05\n",
    "print(\"p value is \" + str(p)) \n",
    "if p <= alpha: \n",
    "    print('reject the null hypothesis at the 5% level') \n",
    "else: \n",
    "    print('fail to reject the null hypothesis under the 5% level')\n",
    "    \n",
    "odds_ratio = (45/35)/(52/33)\n",
    "print ('odds-ratio is', odds_ratio)\n",
    "\n",
    "p2 = str(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value is 0.7489122792634635\n",
      "fail to reject the null hypothesis under the 5% level\n",
      "odds-ratio is 1.1755102040816328\n"
     ]
    }
   ],
   "source": [
    "# Pentobarbital (100 mg):\n",
    "from scipy.stats import chi2_contingency \n",
    "   \n",
    "data = [[45, 35], [35, 32]] \n",
    "stat, p, dof, expected = chi2_contingency(data) \n",
    "  \n",
    "alpha = 0.05\n",
    "print(\"p value is \" + str(p)) \n",
    "if p <= alpha: \n",
    "    print('reject the null hypothesis at the 5% level') \n",
    "else: \n",
    "    print('fail to reject the null hypothesis under the 5% level')\n",
    "    \n",
    "odds_ratio = (45/35)/(35/32)\n",
    "print ('odds-ratio is', odds_ratio)\n",
    "\n",
    "p3 = str(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value is 0.1395431162972681\n",
      "fail to reject the null hypothesis under the 5% level\n",
      "odds-ratio is 1.667953667953668\n"
     ]
    }
   ],
   "source": [
    "# Pentobarbital (150 mg):\n",
    "from scipy.stats import chi2_contingency \n",
    "   \n",
    "data = [[45, 37], [35, 48]] \n",
    "stat, p, dof, expected = chi2_contingency(data) \n",
    "  \n",
    "alpha = 0.05\n",
    "print(\"p value is \" + str(p)) \n",
    "if p <= alpha: \n",
    "    print('reject the null hypothesis at the 5% level') \n",
    "else: \n",
    "    print('fail to reject the null hypothesis under the 5% level')\n",
    "    \n",
    "odds_ratio = (45/35)/(37/48)\n",
    "print ('odds-ratio is', odds_ratio)\n",
    "\n",
    "p4 = str(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for Chlorpromazine the null hypothesis was rejected at the 5% level. Fot the other types of drugs failed to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holm - Bonferroni method:\n",
    "p1 = float(p1)\n",
    "p2 = float(p2)\n",
    "p3 = float(p3)\n",
    "p4 = float(p4)\n",
    "p_values = [p1, p2, p3, p4]\n",
    "p_sorted = sorted (p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(4):\n",
    "    if p_sorted[i] <= alpha/(4-i):\n",
    "        counter = counter + 1\n",
    "            \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\implies$ don't reject the null hypothesis for p2 and stop. The result is Reject $H_{0(1)}$ and fail to reject $H_{0(2)}$, $H_{0(3)}$ , $H_{0(4)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method bonferroni: reject=\n",
      "[ True False False False]\n",
      " with p-values = \n",
      "[0.04511969 0.55817247 1.         1.        ]\n",
      "Method fdr_bh    : reject=\n",
      "[ True False False False]\n",
      " with p-values = \n",
      "[0.04511969 0.27908623 0.74891228 0.74891228]\n"
     ]
    }
   ],
   "source": [
    "# Bonferroni and Benjamini-Hochberg methods\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "for method in [\"bonferroni\", \"fdr_bh\"]:\n",
    "    reject, pvals, _, _ = multipletests(p_values, method=method, returnsorted=True)\n",
    "    print(f\"Method {method:10s}: reject=\\n{reject}\\n with p-values = \\n{pvals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\implies$ Reject $H_{0(1)}$ and fail to reject $H_{0(2)}$, $H_{0(3)}$ , $H_{0(4)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: permutation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we will use the famous Iris dataset, originaly studied by R.A. Fisher himself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select two species: *setosa* and *virginica* and study the sepal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[iris.species == 'setosa']['sepal_width'].values\n",
    "Y = iris[iris.species == 'virginica']['sepal_width'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the hypothesis $H_0$: \"quantiles of level 0.2 of both flowers are equal\" vs $H_1$: \"quantile of level 0.2 (20 percentile, lower 20%) of the sepal width of *setosa* flowers is  larger than that of *virginica* flowers\". Use permutation test, approximate the full permutation distribution with 10,000 samples. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3999999999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xp = np.quantile(X, 0.2)\n",
    "Yp = np.quantile(Y, 0.2)\n",
    "T = np.abs(Xp-Yp)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_permutation_criteria(func, sample1, sample2, nruns):\n",
    "    l1 = len(sample1)\n",
    "    l2 = len(sample2)\n",
    "    \n",
    "    t_obs = func(sample1, sample2)\n",
    "    sample_joint = np.r_[sample1, sample2]\n",
    "    counter = 0.\n",
    "    for r in range(nruns):\n",
    "        sample_joint = np.random.permutation(sample_joint)\n",
    "        t = func(sample_joint[:l1], sample_joint[l1:])\n",
    "        counter += t > t_obs    \n",
    "    return counter / nruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Got p-value = 0.000'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = lambda sample1, sample2: np.abs(np.quantile(X, 0.2)-np.quantile(sample2, 0.2))\n",
    "\n",
    "pvalue = approximate_permutation_criteria(T, X, Y, nruns=10000)\n",
    "f\"Got p-value = {pvalue:.3f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, reject the null hypothesis under any significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: computational approach to hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended reading: http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following dataset (service hours between failures of the air-conditioning equipment in a Boeing 720 jet aircraft , Proschan, 1963):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([3, 5, 7, 18, 43, 85, 91, 98, 100, 130, 230, 487])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample was sorted for easier presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute an estimate of the median time between failures (1 point)\n",
    "2. Consider the null hypothesis $H_0$ to be: \"median time between failures is one week\" (1 point)\n",
    "3. What family of distributions will you choose for this kind of data under $H_0$? (1 point)\n",
    "4. Choose a test statistic to measure the deviation from $H_0$ (1 point)\n",
    "5. Check whether you can reject $H_0$ at significance level 5% and calculate the corresponding approximate $p$-value. Use 10,000 simulations for your experiment (1 point)\n",
    "6. Plot histogram of the simulated values of the test statistic and mark the observed value and threshold that you obtained (1 bouns point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yw = np.array([3/168, 5/168, 7/168, 18/168, 43/168, 85/168, 91/168, 98/168, 100/168, 130/168, 230/168, 487/168])\n",
    "medianweek = np.median(Yw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0: medianweek = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli distribution: each observation has one of two outcomes - it lies above or below the choosen median. Probability that lies above = probability that lies below = 0.5. Hence, S (the count of deviations from the median) follows a binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3094010767585034"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as sps\n",
    "from math import sqrt\n",
    "S = 10\n",
    "n = 12\n",
    "Z = (S - 0.5*n)/(0.5*sqrt(n))\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010460667668896972"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue = 1 - sps.norm.cdf(Z)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.309 > 1.96 and pvalue is less than alpha = 0.05 $\\implies$ reject the null hypothesis: medianweek is different than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(delta, data, iterations):\n",
    "    count = 0.0\n",
    "    for i in range(iterations):\n",
    "        if np.median(data)==delta:\n",
    "            count += 1\n",
    "    return count/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value (1, Yw, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\implies$ reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: power analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1861, 10 essays appeared in the New Orleans Daily Crescent. They\n",
    "were signed “Quintus Curtius Snodgrass” and some people suspected\n",
    "they were actually written by Mark Twain. To investigate this, we will\n",
    "consider the proportion of three letter words found in an author’s work.\n",
    "From eight Twain essays we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([.225, .262, .217, .240, .230, .229, .235, .217])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 10 Snodgrass essays we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([.209, .205, .196, .210, .202, .207, .224, .223, .220, .201])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Perform a Wald test for equality of the means. Use the nonparametric plug-in estimator. Report the p-value and a 95% confidence\n",
    "interval for the difference of means. What do you conclude? (1.5 points)\n",
    "2. Now use a permutation test to avoid the use of large sample methods.\n",
    "What is your conclusion? (Brinegar (1963)) (1.5 points)\n",
    "3. Assume that samples do indeed come from different populations. Additionally, observed sample means and variaces for the two samples are equal to the true values for the respective population. Estimate the power of the two tests above under two model distributions for the data: Normal and [Beta](https://en.wikipedia.org/wiki/Beta_distribution). Use the same family for both samples (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Got statistic = 3.945 with p-value = 7.9926649561458e-05'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wald_test_for_means(sample1, sample2):\n",
    "    mean = np.mean(sample1) - np.mean(sample2)\n",
    "    se = np.sqrt(np.var(sample1) / len(sample1) + np.var(sample2) / len(sample2))\n",
    "    statistic = np.abs(mean / se)\n",
    "    pvalue = 2 * sps.norm.cdf(-np.abs(statistic))\n",
    "    return statistic, pvalue\n",
    "\n",
    "statistic, pvalue = wald_test_for_means(X, Y)\n",
    "\n",
    "f\"Got statistic = {statistic:.3f} with p-value = {pvalue}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval is ( 0.011156701425582985 0.03319329857441702 )\n"
     ]
    }
   ],
   "source": [
    "se = np.sqrt(np.var(X) / len(X) + np.var(Y) / len(Y))\n",
    "CI1 = np.mean(X)-np.mean(Y) - 1.96*se\n",
    "CI2 = np.mean(X)-np.mean(Y) + 1.96*se\n",
    "print (\"95% Confidence Interval is (\",CI1, CI2, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reject the hypothesis that means are equal. 95% confident that the difference in the above mentioned interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_permutation_criteria(func, sample1, sample2, nruns):\n",
    "    l1 = len(sample1)\n",
    "    l2 = len(sample2)\n",
    "    \n",
    "    t_obs = func(sample1, sample2)\n",
    "    sample_joint = np.r_[sample1, sample2]\n",
    "    counter = 0.\n",
    "    for r in range(nruns):\n",
    "        sample_joint = np.random.permutation(sample_joint)\n",
    "        t = func(sample_joint[:l1], sample_joint[l1:])\n",
    "        counter += t > t_obs    \n",
    "    return counter / nruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = lambda sample1, sample2: np.mean(sample1) - np.mean (sample2)\n",
    "\n",
    "pvalue = approximate_permutation_criteria(T, X, Y, nruns=10000)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-value of the permutation test is much bigger than was before."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
